
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Helper Functions &#8212; Brown Water Python  documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples" href="examples.html" />
    <link rel="prev" title="The Token Types" href="tokens.html" />
 
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

    <script type="text/javascript" src="_static/copybutton.js"></script>
 
  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
              <div class="related top">
                &nbsp;
  <nav id="rellinks">
    <ul>
        <li>
          &larr;
          <a href="tokens.html" title="Previous document">The Token Types</a>
        </li>
        <li>
          <a href="examples.html" title="Next document">Examples</a>
          &rarr;
        </li>
    </ul>
  </nav>
              </div>
          

          <div class="body" role="main">
            
  <div class="section" id="helper-functions">
<h1>Helper Functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h1>
<p>In addition to the primary <a class="reference internal" href="usage.html"><span class="doc std std-doc"><code class="docutils literal notranslate"><span class="pre">tokenize()</span></code></span></a> entry-point, the
<code class="docutils literal notranslate"><span class="pre">tokenize</span></code> module has several additional helper functions.</p>
<div class="section" id="untokenize-iterable">
<span id="untokenize"></span><h2><code class="docutils literal notranslate"><span class="pre">untokenize(iterable)</span></code><a class="headerlink" href="#untokenize-iterable" title="Permalink to this headline">¶</a></h2>
<p>Converts an iterable of tokens into a bytes string. The string is encoded
using the encoding of the <a class="reference internal" href="tokens.html#encoding"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">ENCODING</span></code></span></a> token. If there
is no <code class="docutils literal notranslate"><span class="pre">ENCODING</span></code> token present, the string is returned decoded (a <code class="docutils literal notranslate"><span class="pre">str</span></code>
instead of <code class="docutils literal notranslate"><span class="pre">bytes</span></code>). The iterable can be <code class="docutils literal notranslate"><span class="pre">TokenInfo</span></code> objects, or tuples of
<code class="docutils literal notranslate"><span class="pre">(TOKEN_TYPE,</span> <span class="pre">TOKEN_STRING)</span></code>.</p>
<p>This function always round-trips in one direction, namely,
<code class="docutils literal notranslate"><span class="pre">tokenize(io.BytesIO(untokenize(tokens)).readline)</span></code> will always return the
same tokens.</p>
<p>If full <code class="docutils literal notranslate"><span class="pre">TokenInfo</span></code> tuples are given with correct <code class="docutils literal notranslate"><span class="pre">start</span></code> and <code class="docutils literal notranslate"><span class="pre">end</span></code>
information (iterable of 5-tuples), this function also round-trips in the
other direction, for the most part (it assumes space characters between
tokens). However, be aware that the <code class="docutils literal notranslate"><span class="pre">start</span></code> and <code class="docutils literal notranslate"><span class="pre">end</span></code> tuples must be
nondecreasing. If the <code class="docutils literal notranslate"><span class="pre">start</span></code> of one token is before the <code class="docutils literal notranslate"><span class="pre">end</span></code> of the previous
token, it raises <code class="docutils literal notranslate"><span class="pre">ValueError</span></code>. Therefore, if you want to modify tokens and use
<code class="docutils literal notranslate"><span class="pre">untokenize()</span></code> to convert back to a string, using full 5-tuples, you must keep
track of and maintain the line and column information in <code class="docutils literal notranslate"><span class="pre">start</span></code> and <code class="docutils literal notranslate"><span class="pre">end</span></code>.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tokenize</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">io</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">string</span> <span class="o">=</span> <span class="sa">b</span><span class="s1">&#39;sum([[1, 2]][0])&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenize</span><span class="o">.</span><span class="n">untokenize</span><span class="p">(</span><span class="n">tokenize</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">string</span><span class="p">)</span><span class="o">.</span><span class="n">readline</span><span class="p">))</span>
<span class="go">b&#39;sum([[1, 2]][0])&#39;</span>
</pre></div>
</div>
<p>If only the token type and token names are given (iterable of 2-tuples),
<code class="docutils literal notranslate"><span class="pre">untokenize()</span></code> does not round-trip, and in fact, for any nontrivial input, the
resulting bytes string will be very different than the original input. This is
because <code class="docutils literal notranslate"><span class="pre">untokenize()</span></code> adds spaces after certain tokens to ensure the
resulting string is syntactically valid (or rather, to ensure that it
tokenizes back in the same way).</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenize</span><span class="o">.</span><span class="n">untokenize</span><span class="p">([(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">string</span><span class="p">)</span><span class="o">.</span><span class="n">readline</span><span class="p">)])</span>
<span class="go">b&#39;sum ([[1 ,2 ]][0 ])&#39;</span>
</pre></div>
</div>
<p>2-tuples and 5-tuples can be mixed (for instance, you can add new tokens to a
list of <code class="docutils literal notranslate"><span class="pre">TokenInfo</span></code> objects using only 2-tuples), but in this case, it will
ignore the column information for the 5-tuples.</p>
<p>Consider this simple example which replaces all <a class="reference internal" href="tokens.html#string"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">STRING</span></code></span></a>
tokens with a list of <a class="reference internal" href="tokens.html#string"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">STRING</span></code></span></a> tokens of individual
characters (making use of implicit string concatenation). Once <code class="docutils literal notranslate"><span class="pre">untokenize()</span></code>
encounters the newly added 2-tuple tokens, it ignores the column information
and uses its own spacing.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ast</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">split_string</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
<span class="gp">... </span>    <span class="sd">&quot;&quot;&quot;</span>
<span class="gp">... </span><span class="sd">    Split string tokens into constituent characters</span>
<span class="gp">... </span><span class="sd">    &quot;&quot;&quot;</span>
<span class="gp">... </span>    <span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">toknum</span><span class="p">,</span> <span class="n">tokstr</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">readline</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="n">toknum</span> <span class="o">==</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">STRING</span><span class="p">:</span>
<span class="gp">... </span>            <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">tokstr</span><span class="p">):</span>
<span class="gp">... </span>                <span class="n">new_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">toknum</span><span class="p">,</span> <span class="nb">repr</span><span class="p">(</span><span class="n">char</span><span class="p">)))</span>
<span class="gp">... </span>        <span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">new_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">toknum</span><span class="p">,</span> <span class="n">tokstr</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">line</span><span class="p">))</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">untokenize</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">split_string</span><span class="p">(</span><span class="s2">&quot;print(&#39;hello &#39;) and print(&#39;world&#39;)&quot;</span><span class="p">)</span>
<span class="go">&quot;print(&#39;h&#39; &#39;e&#39; &#39;l&#39; &#39;l&#39; &#39;o&#39; &#39; &#39;)and print (&#39;w&#39; &#39;o&#39; &#39;r&#39; &#39;l&#39; &#39;d&#39;)&quot;</span>
</pre></div>
</div>
<p>If you want to use the <code class="docutils literal notranslate"><span class="pre">tokenize</span></code> module to extend the Python language
injecting or modifying tokens in a token stream, then using <code class="docutils literal notranslate"><span class="pre">exec</span></code> or <code class="docutils literal notranslate"><span class="pre">eval</span></code>
to convert the resulting source into executable code, and you do not care what
the code itself looks like, you can simply pass this function tuples of
<code class="docutils literal notranslate"><span class="pre">(TOKEN_TYPE,</span> <span class="pre">TOKEN_STRING)</span></code> and it will work fine. However, if your end goal
is to translate code in a human-readable way, you must keep track of line and
column information near the tokens you modify. The <code class="docutils literal notranslate"><span class="pre">tokenize</span></code> module does not
provide any tools to help with this.</p>
</div>
<div class="section" id="detect-encoding-readline">
<span id="detect-encoding"></span><h2><code class="docutils literal notranslate"><span class="pre">detect_encoding(readline)</span></code><a class="headerlink" href="#detect-encoding-readline" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference external" href="https://docs.python.org/3/library/tokenize.html#tokenize.detect_encoding">official
docs</a>
for this function are helpful. This is the function used by <code class="docutils literal notranslate"><span class="pre">tokenize()</span></code> to
generate the <a class="reference internal" href="tokens.html#encoding"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">ENCODING</span></code></span></a> token. It can be used separately to
determine the encoding of some Python code. The calling syntax is the <a class="reference internal" href="usage.html#calling-syntax"><span class="std std-ref">same as
for <code class="docutils literal notranslate"><span class="pre">tokenize()</span></code></span></a>.</p>
<p>Returns a tuple of the encoding, and a list of any lines (in bytes) that it
has read from the function (it will read at most two lines from the file).
Invalid encodings will cause it to raise a
<a class="reference internal" href="usage.html#syntaxerror"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">SyntaxError</span></code></span></a>.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenize</span><span class="o">.</span><span class="n">detect_encoding</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="sa">b</span><span class="s1">&#39;# -*- coding: ascii -*-&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">readline</span><span class="p">)</span>
<span class="go">(&#39;ascii&#39;, [b&#39;# -*- coding: ascii -*-&#39;])</span>
</pre></div>
</div>
<p>This function should be used to detect the encoding of a Python source file
before opening it in text mode. For example</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;file.py&#39;</span><span class="p">,</span> <span class="s1">&#39;br&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">encoding</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">detect_encoding</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;file.py&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="n">encoding</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="o">...</span>
</pre></div>
</div>
<p>Otherwise, the text read from the file may not be parsable as Python. For
example, <code class="docutils literal notranslate"><span class="pre">ast.parse</span></code> may fail if text from the file is read with the wrong
encoding. For example, if a file starts with a <a class="reference external" href="https://en.wikipedia.org/wiki/Byte_order_mark">Unicode BOM
character</a>, <code class="docutils literal notranslate"><span class="pre">ast.parse</span></code> will
fail if the file is not opened with the proper encoding.</p>
</div>
<div class="section" id="tokenize-open-filename">
<span id="tokenize-open"></span><h2><code class="docutils literal notranslate"><span class="pre">tokenize.open(filename)</span></code><a class="headerlink" href="#tokenize-open-filename" title="Permalink to this headline">¶</a></h2>
<p>This is an alternative to the built-in <code class="docutils literal notranslate"><span class="pre">open()</span></code> function that automatically
opens a Python file in text mode with the correct encoding, as detected by
<a class="reference internal" href="#detect-encoding"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">detect_encoding()</span></code></span></a>.</p>
<p>This function is not particularly useful in conjunction with the <code class="docutils literal notranslate"><span class="pre">tokenize()</span></code>
function (remember that <code class="docutils literal notranslate"><span class="pre">tokenize()</span></code> requires opening a file in binary mode,
whereas this function opens it in text mode). Rather, this is a function that
uses the functionality of the <code class="docutils literal notranslate"><span class="pre">tokenize</span></code> module, in particular,
<code class="docutils literal notranslate"><span class="pre">detect_encoding()</span></code>, to provide a higher level task that would be difficult to
do otherwise (opening a Python source file in text mode using the syntactically
correct encoding).</p>
</div>
<div class="section" id="command-line-usage">
<h2>Command Line Usage<a class="headerlink" href="#command-line-usage" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">tokenize</span></code> module can be called from the command line using <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">tokenize</span> <span class="pre">filename.py</span></code>. This prints three columns, representing the start-end
line and column positions, the token type, and the token string. If the <code class="docutils literal notranslate"><span class="pre">-e</span></code>
flag is used, the token type for operators is the exact type. Otherwise the
<a class="reference internal" href="tokens.html#op"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">OP</span></code></span></a> type is used.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python -m tokenize example.py
<span class="m">0</span>,0-0,0:            ENCODING       <span class="s1">&#39;utf-8&#39;</span>
<span class="m">1</span>,0-1,43:           COMMENT        <span class="s1">&#39;# This is a an example file to be tokenized&#39;</span>
<span class="m">1</span>,43-1,44:          NL             <span class="s1">&#39;\n&#39;</span>
<span class="m">2</span>,0-2,1:            NL             <span class="s1">&#39;\n&#39;</span>
<span class="m">3</span>,0-3,3:            NAME           <span class="s1">&#39;def&#39;</span>
<span class="m">3</span>,4-3,7:            NAME           <span class="s1">&#39;two&#39;</span>
<span class="m">3</span>,7-3,8:            OP             <span class="s1">&#39;(&#39;</span>
<span class="m">3</span>,8-3,9:            OP             <span class="s1">&#39;)&#39;</span>
<span class="m">3</span>,9-3,10:           OP             <span class="s1">&#39;:&#39;</span>
<span class="m">3</span>,10-3,11:          NEWLINE        <span class="s1">&#39;\n&#39;</span>
<span class="m">4</span>,0-4,4:            INDENT         <span class="s1">&#39;    &#39;</span>
<span class="m">4</span>,4-4,10:           NAME           <span class="s1">&#39;return&#39;</span>
<span class="m">4</span>,11-4,12:          NUMBER         <span class="s1">&#39;1&#39;</span>
<span class="m">4</span>,13-4,14:          OP             <span class="s1">&#39;+&#39;</span>
<span class="m">4</span>,15-4,16:          NUMBER         <span class="s1">&#39;1&#39;</span>
<span class="m">4</span>,16-4,17:          NEWLINE        <span class="s1">&#39;\n&#39;</span>
<span class="m">5</span>,0-5,0:            DEDENT         <span class="s1">&#39;&#39;</span>
<span class="m">5</span>,0-5,0:            ENDMARKER      <span class="s1">&#39;&#39;</span>
$ python -m tokenize -e example.py
<span class="m">0</span>,0-0,0:            ENCODING       <span class="s1">&#39;utf-8&#39;</span>
<span class="m">1</span>,0-1,43:           COMMENT        <span class="s1">&#39;# This is a an example file to be tokenized&#39;</span>
<span class="m">1</span>,43-1,44:          NL             <span class="s1">&#39;\n&#39;</span>
<span class="m">2</span>,0-2,1:            NL             <span class="s1">&#39;\n&#39;</span>
<span class="m">3</span>,0-3,3:            NAME           <span class="s1">&#39;def&#39;</span>
<span class="m">3</span>,4-3,7:            NAME           <span class="s1">&#39;two&#39;</span>
<span class="m">3</span>,7-3,8:            LPAR           <span class="s1">&#39;(&#39;</span>
<span class="m">3</span>,8-3,9:            RPAR           <span class="s1">&#39;)&#39;</span>
<span class="m">3</span>,9-3,10:           COLON          <span class="s1">&#39;:&#39;</span>
<span class="m">3</span>,10-3,11:          NEWLINE        <span class="s1">&#39;\n&#39;</span>
<span class="m">4</span>,0-4,4:            INDENT         <span class="s1">&#39;    &#39;</span>
<span class="m">4</span>,4-4,10:           NAME           <span class="s1">&#39;return&#39;</span>
<span class="m">4</span>,11-4,12:          NUMBER         <span class="s1">&#39;1&#39;</span>
<span class="m">4</span>,13-4,14:          PLUS           <span class="s1">&#39;+&#39;</span>
<span class="m">4</span>,15-4,16:          NUMBER         <span class="s1">&#39;1&#39;</span>
<span class="m">4</span>,16-4,17:          NEWLINE        <span class="s1">&#39;\n&#39;</span>
<span class="m">5</span>,0-5,0:            DEDENT         <span class="s1">&#39;&#39;</span>
<span class="m">5</span>,0-5,0:            ENDMARKER      <span class="s1">&#39;&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="helper-functions-related-to-the-parser-module">
<h2>Helper Functions Related to the <code class="docutils literal notranslate"><span class="pre">parser</span></code> Module<a class="headerlink" href="#helper-functions-related-to-the-parser-module" title="Permalink to this headline">¶</a></h2>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The <a class="reference external" href="https://docs.python.org/3/library/symbol.html"><code class="docutils literal notranslate"><span class="pre">symbol</span></code></a> and
<a class="reference external" href="https://docs.python.org/3/library/parser.html"><code class="docutils literal notranslate"><span class="pre">parser</span></code></a> modules are
deprecated as of Python 3.9, as it has moved to a PEG parser. The below does
not necessarily apply to newer Python versions.</p>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">token</span></code> and <code class="docutils literal notranslate"><span class="pre">tokenize</span></code> module mimic the modules in the C parser. Some
additional helper functions are included, even though they are mostly useless
outside of the C parser.</p>
<p>For some context, the Python
<a class="reference external" href="https://docs.python.org/3/reference/grammar.html">grammar</a> contains
<em>terminal</em> and <em>nonterminal</em> nodes. The terminal nodes are the ones that stop
the parsing (they are leaf nodes, that is, no other node in the grammar can be
contained in them). These nodes are represented in uppercase. Every terminal
node in the grammar is a token type, for example, <code class="docutils literal notranslate"><span class="pre">NAME</span></code>, <code class="docutils literal notranslate"><span class="pre">NUMBER</span></code>, or
<code class="docutils literal notranslate"><span class="pre">STRING</span></code>. Most terminal nodes in the <a class="reference external" href="https://github.com/python/cpython/blob/3.9/Grammar/Grammar">grammar
file</a> are
represented by their string value (for instance, the grammar references <code class="docutils literal notranslate"><span class="pre">'('</span></code>
instead of <code class="docutils literal notranslate"><span class="pre">LPAR</span></code>). The C parser re-uses the tokenize node types when it
constructs its internal parse tree. Nonterminal nodes are represented by numbers greater than
<a class="reference internal" href="#nt-offset"><span class="std std-ref"><code class="docutils literal notranslate"><span class="pre">NT_OFFSET</span></code></span></a>. You can see the list of nonterminal nodes
in the
<a class="reference external" href="https://github.com/python/cpython/blob/3.9/Include/graminit.h"><code class="docutils literal notranslate"><span class="pre">graminit.h</span></code></a>
file, or by using the
<a class="reference external" href="https://docs.python.org/3/library/symbol.html"><code class="docutils literal notranslate"><span class="pre">symbol</span></code></a> module.</p>
<p>The <a class="reference external" href="https://docs.python.org/3/library/parser.html"><code class="docutils literal notranslate"><span class="pre">parser</span></code></a> module can be
used from within Python to access the parse tree. The <code class="docutils literal notranslate"><span class="pre">parser</span></code> and <code class="docutils literal notranslate"><span class="pre">symbol</span></code>
modules aren’t discussed further in this guide because the <code class="docutils literal notranslate"><span class="pre">tokenize</span></code> and
<code class="docutils literal notranslate"><span class="pre">ast</span></code> modules are generally preferable for almost all use-cases (see the
<a class="reference internal" href="alternatives.html"><span class="doc std std-doc">alternatives</span></a> section). In particular, the <code class="docutils literal notranslate"><span class="pre">parser</span></code> module
has all the same limitations as the <code class="docutils literal notranslate"><span class="pre">ast</span></code> module (it requires complete,
syntactically valid Python code), but is much more difficult to work with. The
<code class="docutils literal notranslate"><span class="pre">parser</span></code> module exists mainly as a relic from before the <code class="docutils literal notranslate"><span class="pre">ast</span></code> module existed
in the standard library (<code class="docutils literal notranslate"><span class="pre">ast</span></code> was introduced in Python 2.5).</p>
<p>The following example gives an idea of what the <code class="docutils literal notranslate"><span class="pre">parser</span></code> syntax trees look
like for the code <code class="docutils literal notranslate"><span class="pre">(&quot;a&quot;)</span> <span class="pre">+</span> <span class="pre">True</span></code>.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">parser</span> 
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pprint</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">token</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">symbol</span> 
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">pretty</span><span class="p">(</span><span class="n">st</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">l</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">toname</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">t</span><span class="p">[:]):</span>
<span class="gp">... </span>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
<span class="gp">... </span>                <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">ISTERMINAL</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
<span class="gp">... </span>                    <span class="n">t</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">token</span><span class="o">.</span><span class="n">tok_name</span><span class="p">[</span><span class="n">val</span><span class="p">]</span>
<span class="gp">... </span>                <span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>                    <span class="n">t</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">symbol</span><span class="o">.</span><span class="n">sym_name</span><span class="p">[</span><span class="n">val</span><span class="p">]</span>
<span class="gp">... </span>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
<span class="gp">... </span>                <span class="n">toname</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="n">toname</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">l</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">st</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">expr</span><span class="p">(</span><span class="s1">&#39;(&quot;a&quot;) + True&#39;</span><span class="p">)</span> 
<span class="gp">&gt;&gt;&gt; </span><span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">pretty</span><span class="p">(</span><span class="n">st</span><span class="p">))</span> 
<span class="go">[&#39;eval_input&#39;,</span>
<span class="go"> [&#39;testlist&#39;,</span>
<span class="go">  [&#39;test&#39;,</span>
<span class="go">   [&#39;or_test&#39;,</span>
<span class="go">    [&#39;and_test&#39;,</span>
<span class="go">     [&#39;not_test&#39;,</span>
<span class="go">      [&#39;comparison&#39;,</span>
<span class="go">       [&#39;expr&#39;,</span>
<span class="go">        [&#39;xor_expr&#39;,</span>
<span class="go">         [&#39;and_expr&#39;,</span>
<span class="go">          [&#39;shift_expr&#39;,</span>
<span class="go">           [&#39;arith_expr&#39;,</span>
<span class="go">            [&#39;term&#39;,</span>
<span class="go">             [&#39;factor&#39;,</span>
<span class="go">              [&#39;power&#39;,</span>
<span class="go">               [&#39;atom_expr&#39;,</span>
<span class="go">                [&#39;atom&#39;,</span>
<span class="go">                 [&#39;LPAR&#39;, &#39;(&#39;],</span>
<span class="go">                 [&#39;testlist_comp&#39;,</span>
<span class="go">                  [&#39;namedexpr_test&#39;,</span>
<span class="go">                   [&#39;test&#39;,</span>
<span class="go">                    [&#39;or_test&#39;,</span>
<span class="go">                     [&#39;and_test&#39;,</span>
<span class="go">                      [&#39;not_test&#39;,</span>
<span class="go">                       [&#39;comparison&#39;,</span>
<span class="go">                        [&#39;expr&#39;,</span>
<span class="go">                         [&#39;xor_expr&#39;,</span>
<span class="go">                          [&#39;and_expr&#39;,</span>
<span class="go">                           [&#39;shift_expr&#39;,</span>
<span class="go">                            [&#39;arith_expr&#39;,</span>
<span class="go">                             [&#39;term&#39;,</span>
<span class="go">                              [&#39;factor&#39;,</span>
<span class="go">                               [&#39;power&#39;,</span>
<span class="go">                                [&#39;atom_expr&#39;,</span>
<span class="go">                                 [&#39;atom&#39;, [&#39;STRING&#39;, &#39;&quot;a&quot;&#39;]]]]]]]]]]]]]]]]]],</span>
<span class="go">                 [&#39;RPAR&#39;, &#39;)&#39;]]]]]],</span>
<span class="go">            [&#39;PLUS&#39;, &#39;+&#39;],</span>
<span class="go">            [&#39;term&#39;,</span>
<span class="go">             [&#39;factor&#39;,</span>
<span class="go">              [&#39;power&#39;, [&#39;atom_expr&#39;, [&#39;atom&#39;, [&#39;NAME&#39;, &#39;True&#39;]]]]]]]]]]]]]]]]],</span>
<span class="go"> [&#39;NEWLINE&#39;, &#39;&#39;],</span>
<span class="go"> [&#39;ENDMARKER&#39;, &#39;&#39;]]</span>
</pre></div>
</div>
<p>Compare this to the <code class="docutils literal notranslate"><span class="pre">tokenize</span></code> representation seen in the <a class="reference internal" href="intro.html"><span class="doc std std-doc">intro</span></a>,
or the <code class="docutils literal notranslate"><span class="pre">ast</span></code> representation:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ast</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">ast</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s1">&#39;(&quot;a&quot;) + True&#39;</span><span class="p">))</span> 
<span class="go">&quot;Module(body=[Expr(value=BinOp(left=Constant(value=&#39;a&#39;), op=Add(), right=Constant(value=True)))], type_ignores=[])&quot;</span>
</pre></div>
</div>
<p>The following are included in the <code class="docutils literal notranslate"><span class="pre">token</span></code> module, but aren’t particularly
useful outside of the <code class="docutils literal notranslate"><span class="pre">parser</span></code> module.</p>
<div class="section" id="nt-offset">
<span id="id1"></span><h3><code class="docutils literal notranslate"><span class="pre">NT_OFFSET</span></code><a class="headerlink" href="#nt-offset" title="Permalink to this headline">¶</a></h3>
<p>The greatest possible terminal token number. This is not useful unless you
intend to use the <code class="docutils literal notranslate"><span class="pre">parser</span></code> module. <code class="docutils literal notranslate"><span class="pre">tokenize()</span></code> never emits this token. Even
if you are using the <code class="docutils literal notranslate"><span class="pre">parser</span></code> module, you would generally use one of the
functions below instead of this token type. The current value of this constant
is 256.</p>
</div>
<div class="section" id="isterminal-x">
<h3><code class="docutils literal notranslate"><span class="pre">ISTERMINAL(x)</span></code><a class="headerlink" href="#isterminal-x" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">ISTERMINAL(x)</span></code> returns <code class="docutils literal notranslate"><span class="pre">True</span></code> is <code class="docutils literal notranslate"><span class="pre">x</span></code> is a terminal token type. It is
equivalent to <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">&lt;</span> <span class="pre">NT_OFFSET</span></code>. Every token in the <code class="docutils literal notranslate"><span class="pre">token</span></code> module (except for
<code class="docutils literal notranslate"><span class="pre">NT_OFFSET</span></code>) is a terminal node. It returns <code class="docutils literal notranslate"><span class="pre">False</span></code> for every token in the
<code class="docutils literal notranslate"><span class="pre">symbol</span></code> module.</p>
</div>
<div class="section" id="isnonterminal-x">
<h3><code class="docutils literal notranslate"><span class="pre">ISNONTERMINAL(x)</span></code><a class="headerlink" href="#isnonterminal-x" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">ISNONTERMINAL(x)</span></code> returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if <code class="docutils literal notranslate"><span class="pre">x</span></code> is a nonterminal token type. It is
equivalent to <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">&gt;=</span> <span class="pre">NT_OFFSET</span></code>. The only nonterminal “token” in the <code class="docutils literal notranslate"><span class="pre">token</span></code>
module is <code class="docutils literal notranslate"><span class="pre">NT_OFFSET</span></code> itself. It returns <code class="docutils literal notranslate"><span class="pre">True</span></code> for every token in the
<code class="docutils literal notranslate"><span class="pre">symbol</span></code> module.</p>
</div>
<div class="section" id="iseof-x">
<h3><code class="docutils literal notranslate"><span class="pre">ISEOF(x)</span></code><a class="headerlink" href="#iseof-x" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">ISEOF(x)</span></code> returns true if <code class="docutils literal notranslate"><span class="pre">x</span></code> is the end of input marker token type. It is
equivalent to <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">==</span> <span class="pre">ENDMARKER</span></code>. This is also mostly useless, as the
<code class="docutils literal notranslate"><span class="pre">tokenize()</span></code> function ends iteration after it emits this token.</p>
</div>
</div>
</div>


          </div>
              <div class="related bottom">
                &nbsp;
  <nav id="rellinks">
    <ul>
        <li>
          &larr;
          <a href="tokens.html" title="Previous document">The Token Types</a>
        </li>
        <li>
          <a href="examples.html" title="Next document">Examples</a>
          &rarr;
        </li>
    </ul>
  </nav>
              </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">

<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/water-python.jpg" alt="Logo"/>
    
    <h1 class="logo logo-name">Brown Water Python</h1>
    
  </a>
</p>


<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">What is Tokenization?</a></li>
<li class="toctree-l1"><a class="reference internal" href="alternatives.html"><code class="docutils literal notranslate"><span class="pre">tokenize</span></code> vs. Alternatives</a><ul>
<li class="toctree-l2"><a class="reference internal" href="alternatives.html#regular-expressions">Regular Expressions</a></li>
<li class="toctree-l2"><a class="reference internal" href="alternatives.html#tokenize">Tokenize</a></li>
<li class="toctree-l2"><a class="reference internal" href="alternatives.html#ast">AST</a></li>
<li class="toctree-l2"><a class="reference internal" href="alternatives.html#summary">Summary</a><ul>
<li class="toctree-l3"><a class="reference internal" href="alternatives.html#other-standard-library-modules">Other Standard Library Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="alternatives.html#parso">Parso</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="usage.html#calling-syntax">Calling Syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="usage.html#tokeninfo"><code class="docutils literal notranslate"><span class="pre">TokenInfo</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="usage.html#tokeninfo-fields"><code class="docutils literal notranslate"><span class="pre">TokenInfo</span></code> Fields</a><ul>
<li class="toctree-l4"><a class="reference internal" href="usage.html#type"><code class="docutils literal notranslate"><span class="pre">type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="usage.html#string"><code class="docutils literal notranslate"><span class="pre">string</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="usage.html#start-and-end"><code class="docutils literal notranslate"><span class="pre">start</span></code> and <code class="docutils literal notranslate"><span class="pre">end</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="usage.html#line"><code class="docutils literal notranslate"><span class="pre">line</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="usage.html#exceptions">Exceptions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="usage.html#syntaxerror"><code class="docutils literal notranslate"><span class="pre">SyntaxError</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="usage.html#tokenerror"><code class="docutils literal notranslate"><span class="pre">TokenError</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="usage.html#indentationerror"><code class="docutils literal notranslate"><span class="pre">IndentationError</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tokens.html">The Token Types</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tokens.html#the-tok-name-dictionary">The <code class="docutils literal notranslate"><span class="pre">tok_name</span></code> Dictionary</a></li>
<li class="toctree-l2"><a class="reference internal" href="tokens.html#the-tokens">The Tokens</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#endmarker"><code class="docutils literal notranslate"><span class="pre">ENDMARKER</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#name"><code class="docutils literal notranslate"><span class="pre">NAME</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#number"><code class="docutils literal notranslate"><span class="pre">NUMBER</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#string"><code class="docutils literal notranslate"><span class="pre">STRING</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="tokens.html#error-behavior">Error Behavior</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#newline"><code class="docutils literal notranslate"><span class="pre">NEWLINE</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#indent"><code class="docutils literal notranslate"><span class="pre">INDENT</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#dedent"><code class="docutils literal notranslate"><span class="pre">DEDENT</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#rarrow"><code class="docutils literal notranslate"><span class="pre">RARROW</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#ellipsis"><code class="docutils literal notranslate"><span class="pre">ELLIPSIS</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#op"><code class="docutils literal notranslate"><span class="pre">OP</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#await"><code class="docutils literal notranslate"><span class="pre">AWAIT</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#async"><code class="docutils literal notranslate"><span class="pre">ASYNC</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#type-ignore"><code class="docutils literal notranslate"><span class="pre">TYPE_IGNORE</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#type-comment"><code class="docutils literal notranslate"><span class="pre">TYPE_COMMENT</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#errortoken"><code class="docutils literal notranslate"><span class="pre">ERRORTOKEN</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#comment"><code class="docutils literal notranslate"><span class="pre">COMMENT</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#nl"><code class="docutils literal notranslate"><span class="pre">NL</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#encoding"><code class="docutils literal notranslate"><span class="pre">ENCODING</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="tokens.html#n-tokens"><code class="docutils literal notranslate"><span class="pre">N_TOKENS</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Helper Functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#untokenize-iterable"><code class="docutils literal notranslate"><span class="pre">untokenize(iterable)</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#detect-encoding-readline"><code class="docutils literal notranslate"><span class="pre">detect_encoding(readline)</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#tokenize-open-filename"><code class="docutils literal notranslate"><span class="pre">tokenize.open(filename)</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#command-line-usage">Command Line Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="#helper-functions-related-to-the-parser-module">Helper Functions Related to the <code class="docutils literal notranslate"><span class="pre">parser</span></code> Module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#nt-offset"><code class="docutils literal notranslate"><span class="pre">NT_OFFSET</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#isterminal-x"><code class="docutils literal notranslate"><span class="pre">ISTERMINAL(x)</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#isnonterminal-x"><code class="docutils literal notranslate"><span class="pre">ISNONTERMINAL(x)</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#iseof-x"><code class="docutils literal notranslate"><span class="pre">ISEOF(x)</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="examples.html#processing-tokens">Processing Tokens</a><ul>
<li class="toctree-l3"><a class="reference internal" href="examples.html#inside-string"><code class="docutils literal notranslate"><span class="pre">inside_string()</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="examples.html#line-numbers"><code class="docutils literal notranslate"><span class="pre">line_numbers()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="examples.html#indentation-level">Indentation Level</a></li>
<li class="toctree-l3"><a class="reference internal" href="examples.html#mismatched-parentheses">Mismatched Parentheses</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples.html#exercise">Exercise</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="examples.html#modifying-tokens">Modifying Tokens</a><ul>
<li class="toctree-l3"><a class="reference internal" href="examples.html#converting-to">Converting <code class="docutils literal notranslate"><span class="pre">^</span></code> to <code class="docutils literal notranslate"><span class="pre">**</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="examples.html#wrapping-floats-with-decimal-decimal">Wrapping floats with <code class="docutils literal notranslate"><span class="pre">decimal.Decimal</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="examples.html#extending-python-s-syntax">Extending Python’s Syntax</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples.html#emoji-math">Emoji Math</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples.html#backporting-underscores-in-numeric-literals">Backporting Underscores in Numeric Literals</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    
    <div class="footer">
      &copy;2018, Aaron Meurer.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.5.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/helper-functions.md.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
    <span id="forkongithub"><a href="https://github.com/asmeurer/brown-water-python">Fork me on GitHub</a></span>
  </body>
</html>